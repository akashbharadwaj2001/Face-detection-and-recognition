{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face recognition LFW dataset preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR1NQdlVQ7iU"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upR57Izta32N",
        "outputId": "d5125e3b-d236-4c64-df06-03dc66911faa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2 as cv\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gL9uRaPRBIL"
      },
      "source": [
        "**Load the image info file and select persons who have two or more images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbrCt0ZGbdc4",
        "outputId": "889d9641-5932-49fc-a0f2-39c024cf2cb5"
      },
      "source": [
        "annotations = pd.read_csv('/content/drive/MyDrive/lfw_allnames.csv')\n",
        "annotations = annotations[annotations['images'] >= 2]\n",
        "names = list(annotations['name'])\n",
        "np.random.shuffle(names)\n",
        "print('No. of persons is {}'.format(len(names)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No. of persons is 1680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr8us_29RYux"
      },
      "source": [
        "**Preparing the dataset in numpy array**\n",
        "\n",
        "Note: This cell takes time to run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40nPxRuqdNjH",
        "outputId": "b46f54d6-062e-4434-da7e-24a249cfdbf8"
      },
      "source": [
        "names_final = names.copy()\n",
        "face_cascade = cv.CascadeClassifier('/content/drive/MyDrive/Face rec test drawings/haarcascade_frontalface_default.xml')  # Face detection classifiers\n",
        "\n",
        "data = []   # whole dataset\n",
        "counter = 0\n",
        "\n",
        "for name in names:\n",
        "  two_images = []    # List to hold 2 images of same person\n",
        "  flag = 0\n",
        "\n",
        "  for file in (os.listdir('/content/drive/MyDrive/lfw-deepfunneled/lfw-deepfunneled/' + str(name))[0:2]):    # Two images per person\n",
        "    image = cv.imread('/content/drive/MyDrive/lfw-deepfunneled/lfw-deepfunneled/' + str(name) + '/' + str(file))\n",
        "    image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)               # Convert to gray scale\n",
        "    face = face_cascade.detectMultiScale(image, 1.3, 5)         # Detect face(s) in the image\n",
        "    \n",
        "    if(len(face) == 0):            # If no face is detected in the image remove that person from dataset    \n",
        "      flag = 1\n",
        "      names_final.remove(name)\n",
        "      break\n",
        "\n",
        "    # Crop, resize and normalize the face\n",
        "    x, y, w, h = face[0]\n",
        "    image = image[y:y+h, x:x+w]\n",
        "    image = cv.resize(image, (64, 64), interpolation = cv.INTER_AREA)\n",
        "    image = image / 255.0\n",
        "    \n",
        "    two_images.append(image)\n",
        "  \n",
        "  if (flag == 0):\n",
        "    data.append(two_images)\n",
        "    \n",
        "    counter = counter + 1        # To see the progress of the cell\n",
        "    if (counter % 154.5 == 0):\n",
        "      print('\\b\\b\\b\\b\\b\\b{}%'.format(counter * 10 / 154.5))\n",
        "\n",
        "\n",
        "data = np.array(data)\n",
        "print('Total faces detected: {}'.format(2 * len(names_final)))\n",
        "print(data.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b20.0%\n",
            "\b\b\b\b\b\b40.0%\n",
            "\b\b\b\b\b\b60.0%\n",
            "\b\b\b\b\b\b80.0%\n",
            "\b\b\b\b\b\b100.0%\n",
            "Total faces detected: 3090\n",
            "(1545, 2, 64, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljMd3s0HZapG"
      },
      "source": [
        "**Save the prepared data in .npy format**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDcGNoQtVAu3"
      },
      "source": [
        "# np.save('/content/drive/My Drive/lfw-dataset.npy', data)"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}